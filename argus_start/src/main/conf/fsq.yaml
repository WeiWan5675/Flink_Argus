reader:
  type: batch # batch 批处理 stream
  name: mysqlreader
  class: org.weiwan.argus.reader.mysql.MysqlReader
  parallelism: 1
  jdbc:
    url: jdbc:mysql://rm-2zeh739lme9f9hr08eo.mysql.rds.aliyuncs.com:3306/easylife?useUnicode=true&characterEncoding=utf8&autoReconnect=true
    username: easylife_test
    password: EasyLife123
    schema: easylife
    drive: com.mysql.jdbc.Driver
  tableName: easylife_order
  batchSize: 1000 #setFeachSize()的大小 每次从服务器取多少数据
  queryTimeout: 60
  splitField: id #只支持数字类型 通过 sql mod N = 0 N = 1 N = 2 N = 3
  sql:
    filter: id > 100 #a=3,b=5这样
    columns:
    customSql: #如果指定了自定义SQL 那么filter columns 都不会生效 包括increment配置 适用拉取特殊数据时使用
  increment:
    incrField: update_time_dw #如果不指定,默认 select ${columns} from ${table} where 1 = 1 and ${filter} and [splitField mod N = I]
    lastOffset:  #如果指定了该字段,会直接使用,如果不指定,默认是全量拉取 时间类型得  默认值为 1970-01-01 08:00:00  数值型 默认 -1
    enablePolling: false #是否轮询 如果开启轮询 必须要指定increment的属性
    pollingInterval: #轮询间隔




writer:
  type: batch # stream
  name: hdfswriter
  class: org.weiwan.argus.writer.hdfs.HdfsWriter
  parallelism: 3
  batchWriteMode: false #写出模式,是批量写出 还是逐条写出
  batchWriteSize: 10000 #批量写出的大小
  output:
    fileName: easylife_order
    fileSuffix:
    dir: /user/hive/warehouse/easylife_ods.db/source_easylife_order
    lineDelimiter: "\n"
    fieldDelimiter: "\u0001"
    charSetName: UTF-8
    matchMode: Alignment # Alignment 字段位置映射 | Mapping 字段名称匹配
    writeMode: overwrite #overwrite append
    compressType: none
    fileType: Text





channel:
  type:
  name: commonchannel
  class: org.weiwan.argus.channel.CommonChannel